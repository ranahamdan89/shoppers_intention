library(ROSE)
data <- read.csv('data/online_shoppers_intention.csv' , stringsAsFactors = TRUE)
skim(data)
str(data)
summary(data)
head(data)
str(data)
colSums(is.na(data))
table(data$Revenue)
# Recode 'Revenue' into a new binary column with "False" as 0 and "True" as 1
data <- data %>%
mutate(Revenue_binary = ifelse(Revenue == "TRUE", 1, 0))
# Convert 'Revenue_binary' to a factor
data$Revenue_binary <- factor(data$Revenue_binary, levels = c("0", "1"))
# Check the structure of the new column
str(data$Revenue_binary)
prop.table(table(data$Revenue_binary))
# Plot distribution of Revenue_binary
ggplot(data, aes(x = Revenue_binary)) +
geom_bar(fill = "blue") +
labs(title = "Distribution of Revenue_binary", x = "Revenue (0 = No, 1 = Yes)", y = "Count")
# Histogram for ProductRelated_Duration
ggplot(data, aes(x = ProductRelated_Duration)) +
geom_histogram(bins = 30, fill = "orange", color = "black") +
labs(title = "Distribution of ProductRelated_Duration", x = "Time Spent on Product Pages", y = "Frequency")
# Boxplot for BounceRates
ggplot(data, aes(y = BounceRates)) +
geom_boxplot(fill = "green") +
labs(title = "Boxplot of BounceRates", y = "Bounce Rates")
# Revenue vs VisitorType
ggplot(data, aes(x = VisitorType, fill = Revenue_binary)) +
geom_bar(position = "dodge") +
labs(title = "Revenue by Visitor Type", x = "Visitor Type", y = "Count")
# Revenue vs Weekend
ggplot(data, aes(x = Weekend, fill = Revenue_binary)) +
geom_bar(position = "dodge") +
labs(title = "Revenue by Weekend Indicator", x = "Weekend", y = "Count")
# Revenue vs BounceRates
ggplot(data, aes(x = Revenue_binary, y = BounceRates)) +
geom_boxplot(fill = "purple") +
labs(title = "Bounce Rates by Revenue", x = "Revenue (0 = No, 1 = Yes)", y = "Bounce Rates")
# Revenue vs ProductRelated_Duration
ggplot(data, aes(x = Revenue_binary, y = ProductRelated_Duration)) +
geom_boxplot(fill = "pink") +
labs(title = "ProductRelated_Duration by Revenue", x = "Revenue (0 = No, 1 = Yes)", y = "Time Spent on Product Pages")
# Identify numeric columns in the dataset
numeric_columns <- sapply(data , is.numeric)
# Compute the correlation matrix for numeric columns
corr_mat <- cor(data [, numeric_columns], use = "complete.obs")
# Visualize the correlation matrix
library(corrplot)
corrplot(corr_mat, method = "circle")  # Change "circle" to "number", "color", etc., for different styles
data <- select(data, -Revenue )
# Partition the data: 80% training and 20% testing
set.seed(17)
trainIndex <- createDataPartition(data$Revenue_binary, p = 0.8,
list = FALSE,
times = 1)
# Create training and testing datasets
data_train <- data[as.vector(trainIndex), ]
data_test <- data[-as.vector(trainIndex), ]
# Validate the distribution of Revenue_binary in the training set
table(data_train$Revenue_binary)
prop.table(table(data_train$Revenue_binary))
# Validate the distribution of Revenue_binary in the test set
table(data_test$Revenue_binary)
prop.table(table(data_test$Revenue_binary))
# Logistic regression model
Model_LR <- glm(Revenue_binary ~ Month + OperatingSystems + Browser + Region +
TrafficType + VisitorType + Weekend + Administrative +
Administrative_Duration + Informational + Informational_Duration +
ProductRelated + ProductRelated_Duration + BounceRates +
ExitRates + PageValues + SpecialDay,
data = data_train, family = binomial(link = "logit"))
LR_fittedclass <- (Model_LR$fitted.values > 0.5)*1
# Evaluate the Model on Training Data
LR1_Train_CM <- confusionMatrix(as.factor(LR_fittedclass), as.factor(data_train$Revenue_binary), positive="1")
LR1_Train_CM
knitr::opts_chunk$set(echo = TRUE)
library(caret)
library(ggplot2)
library(lattice)
library(skimr)
library(dplyr)
library(randomForest)
library(class)
library(tidyr)
library(stringr)
library(scales)
library(plotly)
library(forcats)
library(rpart)
library(rpart.plot)
library(ROSE)
data <- read.csv('data/online_shoppers_intention.csv' , stringsAsFactors = TRUE)
skim(data)
str(data)
summary(data)
head(data)
str(data)
colSums(is.na(data))
table(data$Revenue)
# Recode 'Revenue' into a new binary column with "False" as 0 and "True" as 1
data <- data %>%
mutate(Revenue_binary = ifelse(Revenue == "TRUE", 1, 0))
# Convert 'Revenue_binary' to a factor
data$Revenue_binary <- factor(data$Revenue_binary, levels = c("0", "1"))
# Check the structure of the new column
str(data$Revenue_binary)
prop.table(table(data$Revenue_binary))
# Plot distribution of Revenue_binary
ggplot(data, aes(x = Revenue_binary)) +
geom_bar(fill = "blue") +
labs(title = "Distribution of Revenue_binary", x = "Revenue (0 = No, 1 = Yes)", y = "Count")
# Histogram for ProductRelated_Duration
ggplot(data, aes(x = ProductRelated_Duration)) +
geom_histogram(bins = 30, fill = "orange", color = "black") +
labs(title = "Distribution of ProductRelated_Duration", x = "Time Spent on Product Pages", y = "Frequency")
# Boxplot for BounceRates
ggplot(data, aes(y = BounceRates)) +
geom_boxplot(fill = "green") +
labs(title = "Boxplot of BounceRates", y = "Bounce Rates")
# Revenue vs VisitorType
ggplot(data, aes(x = VisitorType, fill = Revenue_binary)) +
geom_bar(position = "dodge") +
labs(title = "Revenue by Visitor Type", x = "Visitor Type", y = "Count")
# Revenue vs Weekend
ggplot(data, aes(x = Weekend, fill = Revenue_binary)) +
geom_bar(position = "dodge") +
labs(title = "Revenue by Weekend Indicator", x = "Weekend", y = "Count")
# Revenue vs BounceRates
ggplot(data, aes(x = Revenue_binary, y = BounceRates)) +
geom_boxplot(fill = "purple") +
labs(title = "Bounce Rates by Revenue", x = "Revenue (0 = No, 1 = Yes)", y = "Bounce Rates")
# Revenue vs ProductRelated_Duration
ggplot(data, aes(x = Revenue_binary, y = ProductRelated_Duration)) +
geom_boxplot(fill = "pink") +
labs(title = "ProductRelated_Duration by Revenue", x = "Revenue (0 = No, 1 = Yes)", y = "Time Spent on Product Pages")
# Identify numeric columns in the dataset
numeric_columns <- sapply(data , is.numeric)
# Compute the correlation matrix for numeric columns
corr_mat <- cor(data [, numeric_columns], use = "complete.obs")
# Visualize the correlation matrix
library(corrplot)
corrplot(corr_mat, method = "circle")  # Change "circle" to "number", "color", etc., for different styles
data <- select(data, -Revenue )
# Partition the data: 80% training and 20% testing
set.seed(17)
trainIndex <- createDataPartition(data$Revenue_binary, p = 0.8,
list = FALSE,
times = 1)
# Create training and testing datasets
data_train <- data[as.vector(trainIndex), ]
data_test <- data[-as.vector(trainIndex), ]
# Validate the distribution of Revenue_binary in the training set
table(data_train$Revenue_binary)
prop.table(table(data_train$Revenue_binary))
# Validate the distribution of Revenue_binary in the test set
table(data_test$Revenue_binary)
prop.table(table(data_test$Revenue_binary))
# Null model for training data
model_train_null <- rep(0, nrow(data_train))
model_train_null <- factor(model_train_null, levels = levels(data_train$Revenue_binary))
# Null model for test data
model_test_null <- rep(0, nrow(data_test))
model_test_null <- factor(model_test_null, levels = levels(data_test$Revenue_binary))
# Confusion matrices for training and test sets
cm_train_null <- confusionMatrix(model_train_null, data_train$Revenue_binary, positive = "1")
cm_test_null <- confusionMatrix(model_test_null, data_test$Revenue_binary, positive = "1")
# Print the confusion matrices
print("Confusion Matrix for Training Data (Null Model):")
print(cm_train_null)
print("Confusion Matrix for Test Data (Null Model):")
print(cm_test_null)
# Logistic regression model
Model_LR <- glm(Revenue_binary ~ Month + OperatingSystems + Browser + Region +
TrafficType + VisitorType + Weekend + Administrative +
Administrative_Duration + Informational + Informational_Duration +
ProductRelated + ProductRelated_Duration + BounceRates +
ExitRates + PageValues + SpecialDay,
data = data_train, family = binomial(link = "logit"))
LR_fittedclass <- (Model_LR$fitted.values > 0.5)*1
# Evaluate the Model on Training Data
LR1_Train_CM <- confusionMatrix(as.factor(LR_fittedclass), as.factor(data_train$Revenue_binary), positive="1")
LR1_Train_CM
# Fit the Model on Test Data
Model_LR1 <- glm(Revenue_binary ~ Month + OperatingSystems + Browser + Region +
TrafficType + VisitorType + Weekend + Administrative +
Administrative_Duration + Informational + Informational_Duration +
ProductRelated + ProductRelated_Duration + BounceRates +
ExitRates + PageValues + SpecialDay,
data = data_test, family = binomial(link = "logit"), control = glm.control(maxit = 100))
# Predict on Test Data and Evaluate
LR1_Pred <- predict(Model_LR1, type = "response")
LR1_Pred_Class <- (LR1_Pred > 0.5)*1
LR1_Test_CM <- confusionMatrix(as.factor(LR1_Pred_Class), as.factor(data_test$Revenue_binary), positive="1")
LR1_Test_CM
# Train a decision tree model on the training dataset
#model_tree1 <- rpart(Revenue_binary ~ ., data = data_train)
model_tree1 <- rpart(Revenue_binary ~ Month + OperatingSystems + Browser + Region +
TrafficType + VisitorType + Weekend + Administrative +
Administrative_Duration + Informational + Informational_Duration +
ProductRelated + ProductRelated_Duration + BounceRates +
ExitRates + PageValues + SpecialDay,data = data_train)
# Predict class labels on the training dataset
class_train_tree1 <- predict(model_tree1, type = "class")
# Evaluate the model using a confusion matrix
cm_train_tree1 <- confusionMatrix(as.factor(class_train_tree1), as.factor(data_train$Revenue_binary), positive = "1")
# Display the confusion matrix
cm_train_tree1
# Predict class labels on the test dataset
pred_tree1 <- predict(model_tree1, newdata = data_test, type = "class")
# Evaluate the model using a confusion matrix on the test dataset
cm_test_tree1 <- confusionMatrix(as.factor(pred_tree1), as.factor(data_test$Revenue_binary), positive = "1")
# Display the confusion matrix
cm_test_tree1
# Train a Random Forest model
model_rf1 <- randomForest(Revenue_binary ~ ., data = data_train, importance = TRUE)
# Predict class labels on the training dataset
class_rf1 <- predict(model_rf1, type = "class")
# Evaluate the model using a confusion matrix
cm_train_rf1 <- confusionMatrix(as.factor(class_rf1), as.factor(data_train$Revenue_binary), positive = "1")
# Display the confusion matrix
cm_train_rf1
# Predict class labels on the test dataset
pred_rf1 <- predict(model_rf1, newdata = data_test, type = "class")
# Evaluate the model using a confusion matrix on the test dataset
cm_test_rf1 <- confusionMatrix(as.factor(pred_rf1), as.factor(data_test$Revenue_binary), positive = "1")
# Display the confusion matrix
cm_test_rf1
# Train a Random Forest model
model_rf1 <- randomForest(Revenue_binary ~ ., data = data_train, importance = TRUE)
# Predict class labels on the training dataset
class_rf1 <- predict(model_rf1, type = "class")
# Evaluate the model using a confusion matrix
cm_train_rf1 <- confusionMatrix(as.factor(class_rf1), as.factor(data_train$Revenue_binary), positive = "1")
# Display the confusion matrix
cm_train_rf1
# Predict class labels on the test dataset
pred_rf1 <- predict(model_rf1, newdata = data_test, type = "class")
# Evaluate the model using a confusion matrix on the test dataset
cm_test_rf1 <- confusionMatrix(as.factor(pred_rf1), as.factor(data_test$Revenue_binary), positive = "1")
# Display the confusion matrix
cm_test_rf1
# Train a Random Forest model with class weights
model_rf_weighted <- randomForest(
Revenue_binary ~ .,
data = data_train,
importance = TRUE,
classwt = c("0" = 0.3, "1" = 0.7)  # Adjust weights as needed
)
# Predict class labels on the training dataset
class_rf_train_weighted <- predict(model_rf_weighted, type = "class")
# Evaluate the model using a confusion matrix on the training dataset
cm_train_rf_weighted <- confusionMatrix(
as.factor(class_rf_train_weighted),
as.factor(data_train$Revenue_binary),
positive = "1"
)
# Display the confusion matrix for the training dataset
cm_train_rf_weighted
# Predict class labels on the test dataset
class_rf_test_weighted <- predict(model_rf_weighted, newdata = data_test, type = "class")
# Evaluate the model using a confusion matrix on the test dataset
cm_test_rf_weighted <- confusionMatrix(
as.factor(class_rf_test_weighted),
as.factor(data_test$Revenue_binary),
positive = "1"
)
# Display the confusion matrix for the test dataset
cm_test_rf_weighted
# Apply undersampling to balance the training data
data_train_under <- ovun.sample(Revenue_binary ~ ., data = data_train, method = "under")$data
# Check the class distribution after undersampling
table(data_train_under$Revenue_binary)
# Train Random Forest model on undersampled data
model_rf_under <- randomForest(
Revenue_binary ~ .,
data = data_train_under,
importance = TRUE
)
# Predict class labels on the test dataset
pred_rf_under <- predict(model_rf_under, newdata = data_test, type = "class")
# Evaluate the model using a confusion matrix
cm_test_rf_under <- confusionMatrix(
as.factor(pred_rf_under),
as.factor(data_test$Revenue_binary),
positive = "1"
)
# Display the confusion matrix
cm_test_rf_under
table(data_test$Revenue_binary)
# Separate the majority and minority classes
majority_class <- data_test %>% filter(Revenue_binary == 0)
minority_class <- data_test %>% filter(Revenue_binary == 1)
# Randomly sample from the majority class to match the minority class size
set.seed(123)  # For reproducibility
majority_class_under <- majority_class %>% sample_n(nrow(minority_class))
# Combine the undersampled majority class with the minority class
data_test_balanced <- bind_rows(majority_class_under, minority_class)
# Shuffle the rows
data_test_balanced <- data_test_balanced %>% sample_frac(1)
# Check the class distribution
table(data_test_balanced$Revenue_binary)
# Predict on the balanced test dataset
pred_rf_balanced <- predict(model_rf_under, newdata = data_test_balanced, type = "class")
# Evaluate using a confusion matrix
cm_test_balanced <- confusionMatrix(
as.factor(pred_rf_balanced),
as.factor(data_test_balanced$Revenue_binary),
positive = "1"
)
# Display the confusion matrix
cm_test_balanced
# Extracting variable importance from the Random Forest model
df_imp <- as.data.frame(model_rf1$importance) %>%
arrange(desc(MeanDecreaseGini))  # Use MeanDecreaseGini for ranking
# Converting row names (variable names) into a column for easier plotting
df_imp <- tibble::rownames_to_column(df_imp, "variable")
# Display the importance data
print(df_imp)
# Plotting the variable importance
library(ggplot2)
ggplot(data = df_imp) +
geom_bar(aes(x = reorder(variable, MeanDecreaseGini), y = MeanDecreaseGini),
stat = "identity", fill = "steelblue") +
coord_flip() +
theme_minimal() +
labs(title = "Variable Importance Plot",
x = "Variables",
y = "Mean Decrease in Gini") +
theme(axis.text = element_text(size = 10))
# Extracting variable importance from the Random Forest model
df_imp <- as.data.frame(model_rf1$importance) %>%
arrange(desc(MeanDecreaseGini))  # Use MeanDecreaseGini for ranking
# Converting row names (variable names) into a column for easier plotting
df_imp <- tibble::rownames_to_column(df_imp, "variable")
# Display the importance data
print(df_imp)
# Plotting the variable importance
library(ggplot2)
ggplot(data = df_imp) +
geom_bar(aes(x = reorder(variable, MeanDecreaseGini), y = MeanDecreaseGini),
stat = "identity", fill = "steelblue") +
coord_flip() +
theme_minimal() +
labs(title = "Variable Importance Plot",
x = "Variables",
y = "Mean Decrease in Gini") +
theme(axis.text = element_text(size = 10))
# Subset the data with only the most important variables
important_vars <- c("PageValues", "ExitRates", "ProductRelated_Duration",
"ProductRelated", "Month", "BounceRates",
"Administrative_Duration", "Administrative", "TrafficType")
# Train a Random Forest model using only important variables
model_rf_important <- randomForest(
Revenue_binary ~ .,
data = data_train[, c(important_vars, "Revenue_binary")],
importance = TRUE
)
# Predict class labels on the training dataset
class_rf_important_train <- predict(model_rf_important, type = "class")
# Evaluate the model on the training dataset
cm_train_rf_important <- confusionMatrix(
as.factor(class_rf_important_train),
as.factor(data_train$Revenue_binary),
positive = "1"
)
# Print the confusion matrix for the training dataset
print(cm_train_rf_important)
# Predict class labels on the test dataset
class_rf_important_test <- predict(model_rf_important, newdata = data_test[, c(important_vars, "Revenue_binary")], type = "class")
# Evaluate the model on the test dataset
cm_test_rf_important <- confusionMatrix(
as.factor(class_rf_important_test),
as.factor(data_test$Revenue_binary),
positive = "1"
)
# Print the confusion matrix for the test dataset
print(cm_test_rf_important)
### Model 2.1: Logistic Regression with Important Variables
# Logistic regression model with important variables
Model_LR_important <- glm(Revenue_binary ~ PageValues + ExitRates +
ProductRelated_Duration + ProductRelated +
Month + BounceRates + Administrative_Duration +
Administrative,
data = data_train, family = binomial(link = "logit"))
# Evaluate the model on training data
LR_fittedclass_important <- (Model_LR_important$fitted.values > 0.5) * 1
# Confusion matrix for training data
LR1_Train_CM_important <- confusionMatrix(
as.factor(LR_fittedclass_important),
as.factor(data_train$Revenue_binary),
positive = "1"
)
print(LR1_Train_CM_important)
# Logistic regression on test data
Model_LR1_important <- glm(Revenue_binary ~ PageValues + ExitRates +
ProductRelated_Duration + ProductRelated +
Month + BounceRates + Administrative_Duration +
Administrative,
data = data_test, family = binomial(link = "logit"),
control = glm.control(maxit = 100))
# Predict on test data and evaluate
LR1_Pred_important <- predict(Model_LR1_important, type = "response")
LR1_Pred_Class_important <- (LR1_Pred_important > 0.5) * 1
# Confusion matrix for test data
LR1_Test_CM_important <- confusionMatrix(
as.factor(LR1_Pred_Class_important),
as.factor(data_test$Revenue_binary),
positive = "1"
)
print(LR1_Test_CM_important)
# Train a decision tree model on the training dataset with important variables
model_tree1 <- rpart(Revenue_binary ~ BounceRates + ExitRates + PageValues +
ProductRelated_Duration + Administrative +
Informational_Duration + Month,
data = data_train)
# Predict class labels on the training dataset
class_train_tree1 <- predict(model_tree1, type = "class")
# Evaluate the model using a confusion matrix on the training dataset
cm_train_tree1 <- confusionMatrix(
as.factor(class_train_tree1),
as.factor(data_train$Revenue_binary),
positive = "1"
)
# Display the confusion matrix for the training dataset
cm_train_tree1
r
# Train a decision tree model on the training dataset with important variables
model_tree1 <- rpart(Revenue_binary ~ BounceRates + ExitRates + PageValues +
ProductRelated_Duration + Administrative +
Informational_Duration + Month,
data = data_train)
# Predict class labels on the training dataset
class_train_tree1 <- predict(model_tree1, type = "class")
# Evaluate the model using a confusion matrix on the training dataset
cm_train_tree1 <- confusionMatrix(
as.factor(class_train_tree1),
as.factor(data_train$Revenue_binary),
positive = "1"
)
# Display the confusion matrix for the training dataset
cm_train_tree1
r
# Train a decision tree model on the training dataset with important variables
model_tree1 <- rpart(Revenue_binary ~ BounceRates + ExitRates + PageValues +
ProductRelated_Duration + Administrative +
Informational_Duration + Month,
data = data_train)
# Predict class labels on the training dataset
class_train_tree1 <- predict(model_tree1, type = "class")
# Evaluate the model using a confusion matrix on the training dataset
cm_train_tree1 <- confusionMatrix(
as.factor(class_train_tree1),
as.factor(data_train$Revenue_binary),
positive = "1"
)
# Display the confusion matrix for the training dataset
cm_train_tree1
# Predict class labels on the test dataset
pred_tree1 <- predict(model_tree1, newdata = data_test, type = "class")
# Evaluate the model using a confusion matrix on the test dataset
cm_test_tree1 <- confusionMatrix(
as.factor(pred_tree1),
as.factor(data_test$Revenue_binary),
positive = "1"
)
# Display the confusion matrix for the test dataset
cm_test_tree1
# Function to summarize confusion matrix results
cm_summary <- function(cm, label){
sprintf("%s: Accuracy = %8.4f, Sensitivity = %8.4f, Specificity = %8.4f",
label,
cm$overall["Accuracy"],
cm$byClass["Sensitivity"],
cm$byClass["Specificity"])
}
# Comparing results on training dataset
print("Comparing the results on training dataset")
cat(cm_summary(LR1_Train_CM, "Logistic Regression (All Variables)"), "\n")
cat(cm_summary(LR1_Train_CM_important, "Logistic Regression (Important Variables)"), "\n")
cat(cm_summary(cm_train_tree1, "Decision Tree (All Variables)"), "\n")
cat(cm_summary(cm_train_rf1, "Random Forest (All Variables)"), "\n")
cat(cm_summary(cm_train_rf_important, "Random Forest (Important Variables)"), "\n")
cat(cm_summary(cm_train_rf_weighted, "Random Forest (Weighted)"), "\n")
cat(cm_summary(cm_train_rf_under, "Random Forest (Undersampled)"), "\n")
# Function to summarize confusion matrix results
cm_summary <- function(cm, label){
sprintf("%s: Accuracy = %8.4f, Sensitivity = %8.4f, Specificity = %8.4f",
label,
cm$overall["Accuracy"],
cm$byClass["Sensitivity"],
cm$byClass["Specificity"])
}
# Comparing results on training dataset
print("Comparing the results on training dataset")
cat(cm_summary(LR1_Train_CM, "Logistic Regression (All Variables)"), "\n")
cat(cm_summary(LR1_Train_CM_important, "Logistic Regression (Important Variables)"), "\n")
cat(cm_summary(cm_train_tree1, "Decision Tree (All Variables)"), "\n")
cat(cm_summary(cm_train_rf1, "Random Forest (All Variables)"), "\n")
cat(cm_summary(cm_train_rf_important, "Random Forest (Important Variables)"), "\n")
cat(cm_summary(cm_train_rf_weighted, "Random Forest (Weighted)"), "\n")
# Comparing results on test dataset
print("Comparing the results on test dataset")
cat(cm_summary(LR1_Test_CM, "Logistic Regression (All Variables)"), "\n")
cat(cm_summary(LR1_Test_CM_important, "Logistic Regression (Important Variables)"), "\n")
cat(cm_summary(cm_test_tree1, "Decision Tree (All Variables)"), "\n")
cat(cm_summary(cm_test_rf1, "Random Forest (All Variables)"), "\n")
cat(cm_summary(cm_test_rf_important, "Random Forest (Important Variables)"), "\n")
cat(cm_summary(cm_test_rf_weighted, "Random Forest (Weighted)"), "\n")
cat(cm_summary(cm_test_rf_under, "Random Forest (Undersampled)"), "\n")
